{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXzJ9_yTuX4N"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neighbors import KNeighborsClassifier, KDTree, NearestNeighbors\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Implementing KNN Variants with Varying Dataset Size and Number of Dimensions\n",
        "\n",
        "def measure_knn_performance(X_train, y_train, X_test, y_test, k):\n",
        "    # Naive KNN\n",
        "    start_time = time.time()\n",
        "    naive_knn = KNeighborsClassifier(n_neighbors=k, algorithm='brute')\n",
        "    naive_knn.fit(X_train, y_train)\n",
        "    naive_train_time = time.time() - start_time\n",
        "    start_time = time.time()\n",
        "    naive_y_pred = naive_knn.predict(X_test)\n",
        "    naive_accuracy = accuracy_score(y_test, naive_y_pred)\n",
        "    naive_test_time = time.time() - start_time\n",
        "\n",
        "    # KD-Tree KNN\n",
        "    start_time = time.time()\n",
        "    kdtree = KDTree(X_train, leaf_size=30, metric='euclidean')\n",
        "    kdtree_train_time = time.time() - start_time\n",
        "    start_time = time.time()\n",
        "    _, ind = kdtree.query(X_test, k=k)\n",
        "    kdtree_y_pred = [np.argmax(np.bincount(y_train[neighbors])) for neighbors in ind]\n",
        "    kdtree_accuracy = accuracy_score(y_test, kdtree_y_pred)\n",
        "    kdtree_test_time = time.time() - start_time\n",
        "\n",
        "    # LSH KNN\n",
        "    start_time = time.time()\n",
        "    lsh = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='euclidean')\n",
        "    lsh.fit(X_train)\n",
        "    lsh_train_time = time.time() - start_time\n",
        "    start_time = time.time()\n",
        "    _, ind = lsh.kneighbors(X_test)\n",
        "    lsh_y_pred = [np.argmax(np.bincount(y_train[neighbors])) for neighbors in ind]\n",
        "    lsh_accuracy = accuracy_score(y_test, lsh_y_pred)\n",
        "    lsh_test_time = time.time() - start_time\n",
        "\n",
        "    return {\n",
        "        \"Naive\": {\"Training Time\": naive_train_time,\"Testing Time\": naive_test_time, \"Accuracy\": naive_accuracy},\n",
        "        \"KD-Tree\": {\"Training Time\": kdtree_train_time,\"Testing Time\": kdtree_test_time, \"Accuracy\": kdtree_accuracy},\n",
        "        \"LSH\": {\"Training Time\": lsh_train_time, \"Testing Time\": lsh_test_time,\"Accuracy\": lsh_accuracy}\n",
        "    }\n",
        "\n",
        "def vary_dataset_size_and_dimensions():\n",
        "    dimensions = [2, 5, 10]  # Number of dimensions\n",
        "    dataset_sizes = [1000, 5000, 10000]  # Dataset sizes\n",
        "    k = 5  # Number of neighbors\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for D in dimensions:\n",
        "        for N in dataset_sizes:\n",
        "            informative_features = min(D, 2)\n",
        "            redundant_features = max(0, D - informative_features)\n",
        "            repeated_features = 0  # We don't need repeated features\n",
        "            X, y = make_classification(n_samples=N, n_features=D, n_classes=2, n_informative=informative_features, n_redundant=redundant_features, n_repeated=repeated_features, random_state=42)\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "            result = measure_knn_performance(X_train, y_train, X_test, y_test, k)\n",
        "            results[(D, N)] = result\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the experiments\n",
        "results = vary_dataset_size_and_dimensions()\n",
        "\n",
        "# Print and visualize the results\n",
        "for key, value in results.items():\n",
        "    print(f\"Dimensions: {key[0]}, Dataset Size: {key[1]}\")\n",
        "    for method, metrics in value.items():\n",
        "        print(f\"{method} - Training Time: {metrics['Training Time']:.4f} seconds, Testing Time: {metrics['Testing Time']:.4f} seconds, Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print()\n",
        "# Plot the results\n",
        "dimensions = [2, 5, 10]  # Number of dimensions\n",
        "dataset_sizes = [1000, 5000, 10000]  # Dataset sizes\n",
        "\n",
        "fig, axes = plt.subplots(len(dimensions), len(dataset_sizes), figsize=(15, 10))\n",
        "for i, D in enumerate(dimensions):\n",
        "    for j, N in enumerate(dataset_sizes):\n",
        "        # Get the results for this configuration\n",
        "        result = results[(D, N)]\n",
        "        accuracies = [result[method]['Accuracy'] for method in result]\n",
        "        methods = list(result.keys())\n",
        "\n",
        "        # Plot the accuracies\n",
        "        axes[i, j].bar(methods, accuracies)\n",
        "        axes[i, j].set_title(f\"D={D}, N={N}\")\n",
        "        axes[i, j].set_ylim(0, 1)\n",
        "        axes[i, j].set_ylabel(\"Accuracy\")\n",
        "        axes[i, j].set_xlabel(\"Method\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}